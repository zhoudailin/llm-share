{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af9cbf42-ba71-4f98-85ed-970453c2cc9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05506705b10747d0b1ed906774d8d3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/45448 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function trans_by_llama at 0x7f32e0c43130> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455dc29cfb8341a89e50f0b8ae1d3f8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3175 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1ce40e986aa42b3a9e95a6c92f8bb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0a946035ac457a9af0145a5c66702b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9bae56075044a389b581d28ceae233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/dailin/FrontendCookbook/commit/d85df919d450f3fd0f203800088ff433ef506501', commit_message='Upload dataset', commit_description='', oid='d85df919d450f3fd0f203800088ff433ef506501', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建前端数据集，通过将huggingface的Tensoic/FrontendCookbook数据集翻译为中文进行\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "\n",
    "from datasets import load_dataset\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langsmith import traceable\n",
    "from langsmith.wrappers import wrap_openai\n",
    "\n",
    "reg = r'```\\w+\\n[^`]+```'\n",
    "\n",
    "llm = ChatOpenAI(openai_proxy='http://172.17.208.1:7890')\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"你将扮演一个翻译，将我给你的文字从英文翻译为中文.你只负责翻译，不要回答问题。你也只返回翻译后结果,不要加任何其他文字\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "chain = prompt | llm \n",
    "\n",
    "def question_has_code(example):\n",
    "    return re.search(reg,example['question'])\n",
    "\n",
    "@traceable\n",
    "def trans_by_llama(example):\n",
    "    question =  example['question']\n",
    "    example['instruction'] = chain.invoke({\"input\": question}).content\n",
    "    example['output'] = example['answer']\n",
    "    example['input'] = ''\n",
    "    del example['question']\n",
    "    del example['answer']\n",
    "    return example\n",
    "\n",
    "dataset = load_dataset(\"Tensoic/FrontendCookbook\", split=\"train\")\n",
    "\n",
    "dataset = dataset.filter(question_has_code)\n",
    "dataset = dataset.map(trans_by_llama)\n",
    "\n",
    "dataset.push_to_hub('dailin/FrontendCookbook')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
